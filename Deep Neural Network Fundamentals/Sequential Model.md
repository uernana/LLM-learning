## Lesson 4.1 — Why Sequence Models Matter
1. Topics:

+ Text as sequence

+ One-hot encoding

+ Tokenization basics

+ Next-token prediction

## Lesson 4.2 — RNNs, GRUs, LSTMs
1. Topics:

+ RNN recurrence

+ LSTM gates

+ Why LSTMs help with long-term memory

+ Vanishing gradients

2. Exercise:

+ Build a tiny RNN in PyTorch for sequence prediction

+ Visualize vanishing gradients in RNN
